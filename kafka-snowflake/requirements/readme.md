# ğŸ“Œ Kafka-Snowflake Pipeline  

This project sets up a real-time data pipeline using Kafka and Snowflake.  

## ğŸ“‚ Project Structure  

- **requirements/** â†’ Contains dependencies required for the project  
- **config.json** â†’ Stores credentials and configuration settings  
- **samples/** â†’ Sample data used for testing  
- **producer/** â†’ Kafka producer scripts  
  - **logging/** â†’ Logging for producer processes  
- **consumer/** â†’ Kafka consumer scripts  
  - **logging/** â†’ Logging for consumer processes  
- **transformations/** â†’ Data cleaning and transformation  

## âš™ï¸ What We Are Doing  

- **Kafka Producers** â†’ Sending real-time data  
- **Kafka Consumers** â†’ Receiving data from Kafka  
- **Data Transformation** â†’ Cleaning and structuring messy data  
- **Uploading to Snowflake** â†’ Using `write_pandas` for efficient uploads  
- **Logging** â†’ Tracking producer and consumer activities  

## ğŸš€ How to Run the Project  

### 1ï¸âƒ£ Install Dependencies  
Open **CMD** and run:  
```sh
pip install -r requirements.txt
